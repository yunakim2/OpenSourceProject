{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "koBERT+ClassificationModel2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7q_gkHG1Tp4G",
        "outputId": "7e44d53d-8dd1-414b-e1b7-34a7f980cde8"
      },
      "source": [
        "# 텐서플로우 2.0 기반의 huggingface 라이브러리 패키지 설치\n",
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.8.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from transformers) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.5.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.12 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.96)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QrzLon0kU3IJ"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import *\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import sentencepiece as spm"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmdH6TkDVbtt",
        "outputId": "0a5c8bdc-56e6-46da-b416-4f7f202b58b7"
      },
      "source": [
        "\n",
        "!wget https://raw.githubusercontent.com/yunakim2/OpenSourceProject/stock_report/data/labeled/all1.csv\n",
        "!wget https://raw.githubusercontent.com/yunakim2/OpenSourceProject/stock_report/data/labeled/all.csv"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-25 05:54:35--  https://raw.githubusercontent.com/yunakim2/OpenSourceProject/stock_report/data/labeled/all1.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 299412 (292K) [text/plain]\n",
            "Saving to: ‘all1.csv.1’\n",
            "\n",
            "all1.csv.1          100%[===================>] 292.39K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-06-25 05:54:35 (13.1 MB/s) - ‘all1.csv.1’ saved [299412/299412]\n",
            "\n",
            "--2021-06-25 05:54:35--  https://raw.githubusercontent.com/yunakim2/OpenSourceProject/stock_report/data/labeled/all.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 91761 (90K) [text/plain]\n",
            "Saving to: ‘all.csv.1’\n",
            "\n",
            "all.csv.1           100%[===================>]  89.61K  --.-KB/s    in 0.009s  \n",
            "\n",
            "2021-06-25 05:54:35 (9.41 MB/s) - ‘all.csv.1’ saved [91761/91761]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIJVAi2pgNbM"
      },
      "source": [
        "## **데이터 셋 train / test 데이터로 나눔**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qgbo04LPcUhR",
        "outputId": "32fc7ee0-e0b9-4a7e-ebee-e0cf263e7fce"
      },
      "source": [
        "train = pd.read_csv('all1.csv', encoding=  'utf8', sep=',')\n",
        "train['label']=(train['label']>=0).astype(int)\n",
        "\n",
        "test = pd.read_csv('all.csv', encoding= 'utf8', sep=',', error_bad_lines=False)\n",
        "test['label']=(test['label']>=0).astype(int)\n",
        "\n",
        "\n",
        "print('전체 데이터 개수 : ', (len(train) + len(test)))\n",
        "\n",
        "print('train 데이터 개수 : ', len(train))\n",
        "print('test 데이터 개수 : ', len(test))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "전체 데이터 개수 :  2763\n",
            "train 데이터 개수 :  2086\n",
            "test 데이터 개수 :  677\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "UcpHVKuybb8o",
        "outputId": "08e62832-ea72-40a0-ff6e-6488de7be527"
      },
      "source": [
        "test[:5]"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>title</th>\n",
              "      <th>time</th>\n",
              "      <th>label</th>\n",
              "      <th>ChangeK</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>종목명 to benefit from strong yen, pay high divid...</td>\n",
              "      <td>2016-06-29 15:26:05</td>\n",
              "      <td>1</td>\n",
              "      <td>0.010402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>[Hot-Line] “종목명, 외국인 VIP 증가에 실적 양호”</td>\n",
              "      <td>2016-07-19 08:12:04</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.002088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>종목명, 2분기 영업이익 314억원…전년 동기比 44.8%↑</td>\n",
              "      <td>2016-08-05 17:29:04</td>\n",
              "      <td>1</td>\n",
              "      <td>0.006531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>마카오 카지노경기 26개월만에 회복…파라다이스·종목명 `들썩`</td>\n",
              "      <td>2016-09-02 16:04:04</td>\n",
              "      <td>0</td>\n",
              "      <td>0.010680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>[Hot-Line] “종목명, 중국인 VIP 정체…내년 성장 동력 부재”</td>\n",
              "      <td>2016-11-07 08:45:07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.007851</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  ... label   ChangeK\n",
              "0           0             4  ...     1  0.010402\n",
              "1           1             5  ...     1 -0.002088\n",
              "2           2             6  ...     1  0.006531\n",
              "3           3             7  ...     0  0.010680\n",
              "4           4             8  ...     0  0.007851\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NIN-TehRiOeM"
      },
      "source": [
        "## **데이터 전처리**\n",
        "\n",
        "- ↑, ↓ -> 상승 , 하락으로 변경\n",
        "\n",
        "- [Hot-Line] 제거\n",
        "\n",
        "- 그외 영어, 한글, 숫자 제외 나머지 문자열 제거"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULcIWjY9gOwr"
      },
      "source": [
        "import re\n",
        "def processing(data):\n",
        "  data['title'] = data['title'].str.replace('Hot-Line','')\n",
        "  data['title'] = data['title'].str.replace('↑',' 상승 ')\n",
        "  data['title'] = data['title'].str.replace('↓', ' 하락 ')\n",
        "\n",
        "  data['title'] = data['title'].str.replace('[^a-zA-Z0-9ㄱ-힗 ]', '')\n",
        "  \n",
        "  return data"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "r4nzydtajgNK",
        "outputId": "9d62df81-2e7a-4e2c-d00e-bf73961bdbeb"
      },
      "source": [
        "test = processing(test)\n",
        "train = processing(train)\n",
        "\n",
        "test[:5]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Unnamed: 0.1</th>\n",
              "      <th>title</th>\n",
              "      <th>time</th>\n",
              "      <th>label</th>\n",
              "      <th>ChangeK</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>종목명 to benefit from strong yen pay high dividends</td>\n",
              "      <td>2016-06-29 15:26:05</td>\n",
              "      <td>1</td>\n",
              "      <td>0.010402</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>종목명 외국인 VIP 증가에 실적 양호</td>\n",
              "      <td>2016-07-19 08:12:04</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.002088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>종목명 2분기 영업이익 314억원전년 동기比 448 상승</td>\n",
              "      <td>2016-08-05 17:29:04</td>\n",
              "      <td>1</td>\n",
              "      <td>0.006531</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>마카오 카지노경기 26개월만에 회복파라다이스종목명 들썩</td>\n",
              "      <td>2016-09-02 16:04:04</td>\n",
              "      <td>0</td>\n",
              "      <td>0.010680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>종목명 중국인 VIP 정체내년 성장 동력 부재</td>\n",
              "      <td>2016-11-07 08:45:07</td>\n",
              "      <td>0</td>\n",
              "      <td>0.007851</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Unnamed: 0  Unnamed: 0.1  ... label   ChangeK\n",
              "0           0             4  ...     1  0.010402\n",
              "1           1             5  ...     1 -0.002088\n",
              "2           2             6  ...     1  0.006531\n",
              "3           3             7  ...     0  0.010680\n",
              "4           4             8  ...     0  0.007851\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XbLCoMsf0ok"
      },
      "source": [
        "## **bert input 생성**\n",
        "한글 데이터 분석하기 위해 한국어 데이터로 훈련된 koBERT 사용\n",
        "\n",
        "\n",
        "https://github.com/monologg/KoBERT-NER 에서 kobert를 tokenize 할 수 있는 코드를 가져옴"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFTLnNaoaIz7"
      },
      "source": [
        "import logging\n",
        "import os\n",
        "import unicodedata\n",
        "from shutil import copyfile\n",
        "\n",
        "from transformers import PreTrainedTokenizer\n",
        "\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "VOCAB_FILES_NAMES = {\"vocab_file\": \"tokenizer_78b3253a26.model\",\n",
        "                     \"vocab_txt\": \"vocab.txt\"}\n",
        "\n",
        "PRETRAINED_VOCAB_FILES_MAP = {\n",
        "    \"vocab_file\": {\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/tokenizer_78b3253a26.model\",\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/tokenizer_78b3253a26.model\",\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/tokenizer_78b3253a26.model\"\n",
        "    },\n",
        "    \"vocab_txt\": {\n",
        "        \"monologg/kobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert/vocab.txt\",\n",
        "        \"monologg/kobert-lm\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/kobert-lm/vocab.txt\",\n",
        "        \"monologg/distilkobert\": \"https://s3.amazonaws.com/models.huggingface.co/bert/monologg/distilkobert/vocab.txt\"\n",
        "    }\n",
        "}\n",
        "\n",
        "PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES = {\n",
        "    \"monologg/kobert\": 512,\n",
        "    \"monologg/kobert-lm\": 512,\n",
        "    \"monologg/distilkobert\": 512\n",
        "}\n",
        "\n",
        "PRETRAINED_INIT_CONFIGURATION = {\n",
        "    \"monologg/kobert\": {\"do_lower_case\": False},\n",
        "    \"monologg/kobert-lm\": {\"do_lower_case\": False},\n",
        "    \"monologg/distilkobert\": {\"do_lower_case\": False}\n",
        "}\n",
        "\n",
        "SPIECE_UNDERLINE = u'▁'\n",
        "\n",
        "\n",
        "class KoBertTokenizer(PreTrainedTokenizer):\n",
        "    \"\"\"\n",
        "        SentencePiece based tokenizer. Peculiarities:\n",
        "            - requires `SentencePiece <https://github.com/google/sentencepiece>`_\n",
        "    \"\"\"\n",
        "    vocab_files_names = VOCAB_FILES_NAMES\n",
        "    pretrained_vocab_files_map = PRETRAINED_VOCAB_FILES_MAP\n",
        "    pretrained_init_configuration = PRETRAINED_INIT_CONFIGURATION\n",
        "    max_model_input_sizes = PRETRAINED_POSITIONAL_EMBEDDINGS_SIZES\n",
        "\n",
        "    def __init__(\n",
        "            self,\n",
        "            vocab_file,\n",
        "            vocab_txt,\n",
        "            do_lower_case=False,\n",
        "            remove_space=True,\n",
        "            keep_accents=False,\n",
        "            unk_token=\"[UNK]\",\n",
        "            sep_token=\"[SEP]\",\n",
        "            pad_token=\"[PAD]\",\n",
        "            cls_token=\"[CLS]\",\n",
        "            mask_token=\"[MASK]\",\n",
        "            **kwargs):\n",
        "        super().__init__(\n",
        "            unk_token=unk_token,\n",
        "            sep_token=sep_token,\n",
        "            pad_token=pad_token,\n",
        "            cls_token=cls_token,\n",
        "            mask_token=mask_token,\n",
        "            **kwargs\n",
        "        )\n",
        "\n",
        "        # Build vocab\n",
        "        self.token2idx = dict()\n",
        "        self.idx2token = []\n",
        "        with open(vocab_txt, 'r', encoding='utf-8') as f:\n",
        "            for idx, token in enumerate(f):\n",
        "                token = token.strip()\n",
        "                self.token2idx[token] = idx\n",
        "                self.idx2token.append(token)\n",
        "\n",
        "        try:\n",
        "            import sentencepiece as spm\n",
        "        except ImportError:\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
        "                           \"pip install sentencepiece\")\n",
        "\n",
        "        self.do_lower_case = do_lower_case\n",
        "        self.remove_space = remove_space\n",
        "        self.keep_accents = keep_accents\n",
        "        self.vocab_file = vocab_file\n",
        "        self.vocab_txt = vocab_txt\n",
        "\n",
        "        self.sp_model = spm.SentencePieceProcessor()\n",
        "        self.sp_model.Load(vocab_file)\n",
        "\n",
        "    @property\n",
        "    def vocab_size(self):\n",
        "        return len(self.idx2token)\n",
        "\n",
        "    def get_vocab(self):\n",
        "        return dict(self.token2idx, **self.added_tokens_encoder)\n",
        "\n",
        "    def __getstate__(self):\n",
        "        state = self.__dict__.copy()\n",
        "        state[\"sp_model\"] = None\n",
        "        return state\n",
        "\n",
        "    def __setstate__(self, d):\n",
        "        self.__dict__ = d\n",
        "        try:\n",
        "            import sentencepiece as spm\n",
        "        except ImportError:\n",
        "            logger.warning(\"You need to install SentencePiece to use KoBertTokenizer: https://github.com/google/sentencepiece\"\n",
        "                           \"pip install sentencepiece\")\n",
        "        self.sp_model = spm.SentencePieceProcessor()\n",
        "        self.sp_model.Load(self.vocab_file)\n",
        "\n",
        "    def preprocess_text(self, inputs):\n",
        "        if self.remove_space:\n",
        "            outputs = \" \".join(inputs.strip().split())\n",
        "        else:\n",
        "            outputs = inputs\n",
        "        outputs = outputs.replace(\"``\", '\"').replace(\"''\", '\"')\n",
        "\n",
        "        if not self.keep_accents:\n",
        "            outputs = unicodedata.normalize('NFKD', outputs)\n",
        "            outputs = \"\".join([c for c in outputs if not unicodedata.combining(c)])\n",
        "        if self.do_lower_case:\n",
        "            outputs = outputs.lower()\n",
        "\n",
        "        return outputs\n",
        "\n",
        "    def _tokenize(self, text, return_unicode=True, sample=False):\n",
        "        \"\"\" Tokenize a string. \"\"\"\n",
        "        text = self.preprocess_text(text)\n",
        "\n",
        "        if not sample:\n",
        "            pieces = self.sp_model.EncodeAsPieces(text)\n",
        "        else:\n",
        "            pieces = self.sp_model.SampleEncodeAsPieces(text, 64, 0.1)\n",
        "        new_pieces = []\n",
        "        for piece in pieces:\n",
        "            if len(piece) > 1 and piece[-1] == str(\",\") and piece[-2].isdigit():\n",
        "                cur_pieces = self.sp_model.EncodeAsPieces(piece[:-1].replace(SPIECE_UNDERLINE, \"\"))\n",
        "                if piece[0] != SPIECE_UNDERLINE and cur_pieces[0][0] == SPIECE_UNDERLINE:\n",
        "                    if len(cur_pieces[0]) == 1:\n",
        "                        cur_pieces = cur_pieces[1:]\n",
        "                    else:\n",
        "                        cur_pieces[0] = cur_pieces[0][1:]\n",
        "                cur_pieces.append(piece[-1])\n",
        "                new_pieces.extend(cur_pieces)\n",
        "            else:\n",
        "                new_pieces.append(piece)\n",
        "\n",
        "        return new_pieces\n",
        "\n",
        "    def _convert_token_to_id(self, token):\n",
        "        \"\"\" Converts a token (str/unicode) in an id using the vocab. \"\"\"\n",
        "        return self.token2idx.get(token, self.token2idx[self.unk_token])\n",
        "\n",
        "    def _convert_id_to_token(self, index, return_unicode=True):\n",
        "        \"\"\"Converts an index (integer) in a token (string/unicode) using the vocab.\"\"\"\n",
        "        return self.idx2token[index]\n",
        "\n",
        "    def convert_tokens_to_string(self, tokens):\n",
        "        \"\"\"Converts a sequence of tokens (strings for sub-words) in a single string.\"\"\"\n",
        "        out_string = \"\".join(tokens).replace(SPIECE_UNDERLINE, \" \").strip()\n",
        "        return out_string\n",
        "\n",
        "    def build_inputs_with_special_tokens(self, token_ids_0, token_ids_1=None):\n",
        "        \"\"\"\n",
        "        Build model inputs from a sequence or a pair of sequence for sequence classification tasks\n",
        "        by concatenating and adding special tokens.\n",
        "        A KoBERT sequence has the following format:\n",
        "            single sequence: [CLS] X [SEP]\n",
        "            pair of sequences: [CLS] A [SEP] B [SEP]\n",
        "        \"\"\"\n",
        "        if token_ids_1 is None:\n",
        "            return [self.cls_token_id] + token_ids_0 + [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        sep = [self.sep_token_id]\n",
        "        return cls + token_ids_0 + sep + token_ids_1 + sep\n",
        "\n",
        "    def get_special_tokens_mask(self, token_ids_0, token_ids_1=None, already_has_special_tokens=False):\n",
        "        \"\"\"\n",
        "        Retrieves sequence ids from a token list that has no special tokens added. This method is called when adding\n",
        "        special tokens using the tokenizer ``prepare_for_model`` or ``encode_plus`` methods.\n",
        "        Args:\n",
        "            token_ids_0: list of ids (must not contain special tokens)\n",
        "            token_ids_1: Optional list of ids (must not contain special tokens), necessary when fetching sequence ids\n",
        "                for sequence pairs\n",
        "            already_has_special_tokens: (default False) Set to True if the token list is already formated with\n",
        "                special tokens for the model\n",
        "        Returns:\n",
        "            A list of integers in the range [0, 1]: 0 for a special token, 1 for a sequence token.\n",
        "        \"\"\"\n",
        "\n",
        "        if already_has_special_tokens:\n",
        "            if token_ids_1 is not None:\n",
        "                raise ValueError(\n",
        "                    \"You should not supply a second sequence if the provided sequence of \"\n",
        "                    \"ids is already formated with special tokens for the model.\"\n",
        "                )\n",
        "            return list(map(lambda x: 1 if x in [self.sep_token_id, self.cls_token_id] else 0, token_ids_0))\n",
        "\n",
        "        if token_ids_1 is not None:\n",
        "            return [1] + ([0] * len(token_ids_0)) + [1] + ([0] * len(token_ids_1)) + [1]\n",
        "        return [1] + ([0] * len(token_ids_0)) + [1]\n",
        "\n",
        "    def create_token_type_ids_from_sequences(self, token_ids_0, token_ids_1=None):\n",
        "        \"\"\"\n",
        "        Creates a mask from the two sequences passed to be used in a sequence-pair classification task.\n",
        "        A KoBERT sequence pair mask has the following format:\n",
        "        0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1\n",
        "        | first sequence    | second sequence\n",
        "        if token_ids_1 is None, only returns the first portion of the mask (0's).\n",
        "        \"\"\"\n",
        "        sep = [self.sep_token_id]\n",
        "        cls = [self.cls_token_id]\n",
        "        if token_ids_1 is None:\n",
        "            return len(cls + token_ids_0 + sep) * [0]\n",
        "        return len(cls + token_ids_0 + sep) * [0] + len(token_ids_1 + sep) * [1]\n",
        "\n",
        "    def save_vocabulary(self, save_directory):\n",
        "        \"\"\" Save the sentencepiece vocabulary (copy original file) and special tokens file\n",
        "            to a directory.\n",
        "        \"\"\"\n",
        "        if not os.path.isdir(save_directory):\n",
        "            logger.error(\"Vocabulary path ({}) should be a directory\".format(save_directory))\n",
        "            return\n",
        "\n",
        "        # 1. Save sentencepiece model\n",
        "        out_vocab_model = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_file\"])\n",
        "\n",
        "        if os.path.abspath(self.vocab_file) != os.path.abspath(out_vocab_model):\n",
        "            copyfile(self.vocab_file, out_vocab_model)\n",
        "\n",
        "        # 2. Save vocab.txt\n",
        "        index = 0\n",
        "        out_vocab_txt = os.path.join(save_directory, VOCAB_FILES_NAMES[\"vocab_txt\"])\n",
        "        with open(out_vocab_txt, \"w\", encoding=\"utf-8\") as writer:\n",
        "            for token, token_index in sorted(self.token2idx.items(), key=lambda kv: kv[1]):\n",
        "                if index != token_index:\n",
        "                    logger.warning(\n",
        "                        \"Saving vocabulary to {}: vocabulary indices are not consecutive.\"\n",
        "                        \" Please check that the vocabulary is not corrupted!\".format(out_vocab_txt)\n",
        "                    )\n",
        "                    index = token_index\n",
        "                writer.write(token + \"\\n\")\n",
        "                index += 1\n",
        "\n",
        "        return out_vocab_model, out_vocab_txt"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1H_33hS6g3ee"
      },
      "source": [
        "# koBERT 토크나이즈 임포트\n",
        "tokenizer = KoBertTokenizer.from_pretrained('monologg/kobert')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jaXSaULZhUlU"
      },
      "source": [
        "## **bertClassificationModel의 input으로 변환하기**\n",
        "\n",
        "bertClassifiactionModel의 인풋으로 **토큰, 세그먼트, 마스크**으로 이루어져있어 test,train 문장들을 **토큰 세그먼트,마스크 인풋으로 변환하는 과정이 필요함**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ljR5tPK3h94s"
      },
      "source": [
        "### 1. tokenizer 예시\n",
        "\n",
        "- `tokenizer.tokenize` => 문장을 토큰화\n",
        "- `tokenizer.encode` => 문장을 버트 모델의 인풋 토큰값으로 변경"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iI8uYy2-h8Dt",
        "outputId": "54dc0a43-bb9e-4762-ceab-b0678d13bb5a"
      },
      "source": [
        "print(tokenizer.tokenize(test.iloc[0]['title']))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['▁종목', '명', '▁to', '▁', 'b', 'en', 'e', 'f', 'it', '▁', 'f', 'ro', 'm', '▁', 'st', 'ro', 'n', 'g', '▁', 'y', 'en', '▁', 'p', 'ay', '▁', 'h', 'i', 'g', 'h', '▁', 'd', 'i', 'v', 'id', 'en', 'd', 's']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S12n9GGkiZ0S",
        "outputId": "bb41d0f6-3833-426e-e5b2-1ee1c4cbe729"
      },
      "source": [
        "print(tokenizer.encode(test.iloc[0]['title']))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[2, 4202, 6204, 709, 517, 380, 392, 389, 398, 413, 517, 398, 439, 423, 517, 441, 439, 425, 399, 517, 458, 392, 517, 432, 379, 517, 401, 405, 399, 401, 517, 388, 405, 453, 407, 392, 388, 440, 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WV-8S7QekdJo"
      },
      "source": [
        "### 1. 토큰 인풋 변환\n",
        "\n",
        "문장 토크나이징 후 `tokenizer.encode()` 결과 값으로 문장이 `유효한 값`이면 **1**로, `유효하지 않으면` **0**으로 채워\n",
        "문장 길이가 다르지만 **버트의 인풋길이를 일정하게 고정**하기 위해 버트에서 지정한 문장 길이를 초과하면 패딩값 0으로 채운다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXuVsWJPktZ8",
        "outputId": "5d6f66ee-6e6e-4e19-81b9-e846619ecd52"
      },
      "source": [
        "print(tokenizer.encode(test.iloc[0]['title'], max_length=64, pad_to_max_length=True))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[2, 4202, 6204, 709, 517, 380, 392, 389, 398, 413, 517, 398, 439, 423, 517, 441, 439, 425, 399, 517, 458, 392, 517, 432, 379, 517, 401, 405, 399, 401, 517, 388, 405, 453, 407, 392, 388, 440, 3, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils_base.py:2132: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
            "  FutureWarning,\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRZGxWcNii6p"
      },
      "source": [
        "### 2. 세그멘트 인풋 변환\n",
        "\n",
        "세그멘트는 bert 모형에 들어가 bert 모형에 맞게 고차원으로 임베딩 되는 원리임\n",
        "\n",
        "버트 모형에서 문장이 앞 문장인지, 뒷 문장인지 표현해주는 것이고 \n",
        "**지금 사용하고 있는 dataset은 한문장 이므로 '0'으로 통일한다.**\n",
        "\n",
        "최대 길이를 128로 고정했으므로 세그먼트도 `[0]*128`가 되어야한다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sp_Tug9Rh3d1",
        "outputId": "f5a9fb76-a20d-45f7-dded-67c18e81d160"
      },
      "source": [
        "print([0]*128)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HzysUwcakB0C"
      },
      "source": [
        "### 3. 마스크 인풋\n",
        "\n",
        "토큰 인풋에서 **패딩이 아닌 부분**은 `1` , **패딩인 부분**은 `0`으로 두게 되는 것"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VE_wxsm7g6a4",
        "outputId": "51a1057b-3a8f-4316-e9ef-50f076637876"
      },
      "source": [
        "valid_num = len(tokenizer.encode(test.iloc[0]['title']))\n",
        "print(valid_num * [1] + (128-valid_num) * [0])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMwKV7Gnlala"
      },
      "source": [
        "## **버트 인풋으로 변환하는 함수 구현**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzqhcBFOjSep"
      },
      "source": [
        "def convert_data(data_df):\n",
        "    global tokenizer\n",
        "    \n",
        "    SEQ_LEN = 128 #SEQ_LEN : 버트에 들어갈 인풋의 길이\n",
        "    \n",
        "    tokens, masks, segments, targets = [], [], [], []\n",
        "    \n",
        "    for i in tqdm(range(len(data_df))):\n",
        "        # token : 문장을 토큰화함\n",
        "        token = tokenizer.encode(data_df.iloc[i][DATA_COLUMN], truncation=True, padding='max_length', max_length=SEQ_LEN)\n",
        "       \n",
        "        # 마스크는 토큰화한 문장에서 패딩이 아닌 부분은 1, 패딩인 부분은 0으로 통일\n",
        "        num_zeros = token.count(0)\n",
        "        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\n",
        "        \n",
        "        # 문장의 전후관계를 구분해주는 세그먼트는 문장이 1개밖에 없으므로 모두 0\n",
        "        segment = [0]*SEQ_LEN\n",
        "\n",
        "        # 버트 인풋으로 들어가는 token, mask, segment를 tokens, segments에 각각 저장\n",
        "        tokens.append(token)\n",
        "        masks.append(mask)\n",
        "        segments.append(segment)\n",
        "        \n",
        "        # 정답(상승 : 1 하락 0)을 targets 변수에 저장해 줌\n",
        "        targets.append(data_df.iloc[i][LABEL_COLUMN])\n",
        "\n",
        "    # tokens, masks, segments, 정답 변수 targets를 numpy array로 지정    \n",
        "    tokens = np.array(tokens)\n",
        "    masks = np.array(masks)\n",
        "    segments = np.array(segments)\n",
        "    targets = np.array(targets)\n",
        "\n",
        "    return [tokens, masks, segments], targets\n",
        "\n",
        "# 위에 정의한 convert_data 함수를 불러오는 함수를 정의\n",
        "def load_data(pandas_dataframe):\n",
        "    data_df = pandas_dataframe\n",
        "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
        "    data_df[LABEL_COLUMN] = data_df[LABEL_COLUMN].astype(int)\n",
        "    data_x, data_y = convert_data(data_df)\n",
        "    return data_x, data_y\n",
        "\n",
        "SEQ_LEN = 128\n",
        "BATCH_SIZE = 32\n",
        "# 뉴스 제목 칼럼\n",
        "DATA_COLUMN = 'title'\n",
        "# 상승인지 하락인지를 (1=상승,0=하락) 포함하고 있는 칼럼\n",
        "LABEL_COLUMN = 'label'"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mUnUl3Csp79a"
      },
      "source": [
        "**Train 데이터, Test 데이터 버트 인풋으로 변환**\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sj5f0IEfhSZa",
        "outputId": "4d9871bc-a637-4130-a302-6351ee911a83"
      },
      "source": [
        "train_x, train_y = load_data(train)\n",
        "test_x, test_y = load_data(test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 2086/2086 [00:01<00:00, 1968.91it/s]\n",
            "100%|██████████| 677/677 [00:00<00:00, 1968.47it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKk4pBPuqJTh"
      },
      "source": [
        "## **BertClassificatonModel 활용하여 감성분석 모델 구현**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT-YayPiqIuo",
        "outputId": "d3a462e6-a508-495a-c137-8cd06f7f3cb0"
      },
      "source": [
        "model = TFBertModel.from_pretrained(\"monologg/kobert\", from_pt=True)\n",
        "# 토큰 인풋, 마스크 인풋, 세그먼트 인풋 정의\n",
        "token_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_word_ids')\n",
        "mask_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_masks')\n",
        "segment_inputs = tf.keras.layers.Input((SEQ_LEN,), dtype=tf.int32, name='input_segment')\n",
        "# 인풋이 [토큰, 마스크, 세그먼트]인 모델 정의\n",
        "bert_outputs = model([token_inputs, mask_inputs, segment_inputs])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All PyTorch model weights were used when initializing TFBertModel.\n",
            "\n",
            "All the weights of TFBertModel were initialized from the PyTorch model.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use TFBertModel for predictions without further training.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f131dfb7de0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f131dfb7de0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f1339864dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function wrap at 0x7f1339864dd0> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/array_ops.py:5049: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ra43dtWexay3",
        "outputId": "30664393-b4fa-4c78-a114-298cea788c2e"
      },
      "source": [
        "bert_outputs"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TFBaseModelOutputWithPooling([('last_hidden_state',\n",
              "                               <KerasTensor: shape=(None, 128, 768) dtype=float32 (created by layer 'tf_bert_model')>),\n",
              "                              ('pooler_output',\n",
              "                               <KerasTensor: shape=(None, 768) dtype=float32 (created by layer 'tf_bert_model')>)])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5vi-8jAmMnt"
      },
      "source": [
        "bert_outputs = bert_outputs[1]"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ZlPQjQtqb7I",
        "outputId": "e187577d-7e89-4428-cac6-e53af1190be7"
      },
      "source": [
        "# Rectified Adam 옵티마이저 사용\n",
        "!pip install tensorflow_addons\n",
        "import tensorflow_addons as tfa\n",
        "# 총 batch size * 4 epoch = 2344 * 4\n",
        "opt = tfa.optimizers.RectifiedAdam(lr=5.0e-5, total_steps = 2344*4, warmup_proportion=0.1, min_lr=1e-5, epsilon=1e-08, clipnorm=1.0)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.13.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0FWnnJ46q0BS"
      },
      "source": [
        "sentiment_drop = tf.keras.layers.Dropout(0.5)(bert_outputs)\n",
        "sentiment_first = tf.keras.layers.Dense(1, activation='sigmoid', kernel_initializer=tf.keras.initializers.TruncatedNormal(stddev=0.02))(sentiment_drop)\n",
        "news_model = tf.keras.Model([token_inputs, mask_inputs, segment_inputs], sentiment_first)\n",
        "news_model.compile(optimizer=opt, loss=tf.keras.losses.BinaryCrossentropy(), metrics = ['accuracy'])"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SDJ7iuHnq1_Y",
        "outputId": "3cd6b87d-77f1-4f0c-b5c4-2762cabea3ad"
      },
      "source": [
        "news_model.summary()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_word_ids (InputLayer)     [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_masks (InputLayer)        [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_segment (InputLayer)      [(None, 128)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_bert_model (TFBertModel)     TFBaseModelOutputWit 92186880    input_word_ids[0][0]             \n",
            "                                                                 input_masks[0][0]                \n",
            "                                                                 input_segment[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dropout_37 (Dropout)            (None, 768)          0           tf_bert_model[0][1]              \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 1)            769         dropout_37[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 92,187,649\n",
            "Trainable params: 92,187,649\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-j6WogApq3qO",
        "outputId": "8222504a-e188-4536-d2ea-19ae5ba4aaca"
      },
      "source": [
        "news_model.fit(train_x, train_y, epochs=4, shuffle=True, batch_size=64, validation_data=(test_x, test_y))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/4\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "33/33 [==============================] - ETA: 0s - loss: 0.6888 - accuracy: 0.5594WARNING:tensorflow:The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "WARNING:tensorflow:The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "33/33 [==============================] - 109s 2s/step - loss: 0.6888 - accuracy: 0.5594 - val_loss: 0.6954 - val_accuracy: 0.5199\n",
            "Epoch 2/4\n",
            "33/33 [==============================] - 58s 2s/step - loss: 0.6851 - accuracy: 0.5570 - val_loss: 0.6938 - val_accuracy: 0.5199\n",
            "Epoch 3/4\n",
            "33/33 [==============================] - 58s 2s/step - loss: 0.6856 - accuracy: 0.5599 - val_loss: 0.7012 - val_accuracy: 0.5199\n",
            "Epoch 4/4\n",
            "33/33 [==============================] - 58s 2s/step - loss: 0.6829 - accuracy: 0.5690 - val_loss: 0.7019 - val_accuracy: 0.5199\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f12261b2110>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF_fABDGq8SZ"
      },
      "source": [
        "훈련 모델 예측 성능을 F1 - Score로 체크하기 위한 함수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QD6YWiSRrB26"
      },
      "source": [
        "def predict_convert_data(data_df):\n",
        "    global tokenizer\n",
        "    tokens, masks, segments = [], [], []\n",
        "    \n",
        "    for i in tqdm(range(len(data_df))):\n",
        "\n",
        "        token = tokenizer.encode(data_df.iloc[i]['title'], max_length=SEQ_LEN, truncation=True, padding='max_length')\n",
        "        num_zeros = token.count(0)\n",
        "        mask = [1]*(SEQ_LEN-num_zeros) + [0]*num_zeros\n",
        "        segment = [0]*SEQ_LEN\n",
        "\n",
        "        tokens.append(token)\n",
        "        segments.append(segment)\n",
        "        masks.append(mask)\n",
        "\n",
        "    tokens = np.array(tokens)\n",
        "    masks = np.array(masks)\n",
        "    segments = np.array(segments)\n",
        "    return [tokens, masks, segments]\n",
        "\n",
        "# 위에 정의한 convert_data 함수를 불러오는 함수를 정의\n",
        "def predict_load_data(pandas_dataframe):\n",
        "    data_df = pandas_dataframe\n",
        "    data_df[DATA_COLUMN] = data_df[DATA_COLUMN].astype(str)\n",
        "    data_x = predict_convert_data(data_df)\n",
        "    return data_x"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sA1UKwhbrE65",
        "outputId": "98d55cee-ad71-4493-d2b9-7b83a460933a"
      },
      "source": [
        "test_set = predict_load_data(test)\n",
        "preds = news_model.predict(test_set)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 677/677 [00:00<00:00, 2770.05it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AXXxV1yIrFo6",
        "outputId": "1bbf6c6b-c3e2-4934-a315-4fc76eef3144"
      },
      "source": [
        "# 부정이면 0, 긍정이면 1 출력\n",
        "preds"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.5485114 ],\n",
              "       [0.58797246],\n",
              "       [0.58992994],\n",
              "       [0.589275  ],\n",
              "       [0.5888059 ],\n",
              "       [0.5817048 ],\n",
              "       [0.5824055 ],\n",
              "       [0.58225584],\n",
              "       [0.5883516 ],\n",
              "       [0.5891346 ],\n",
              "       [0.5810852 ],\n",
              "       [0.58915377],\n",
              "       [0.58798796],\n",
              "       [0.5884642 ],\n",
              "       [0.5890902 ],\n",
              "       [0.58771974],\n",
              "       [0.58796066],\n",
              "       [0.5883722 ],\n",
              "       [0.58857286],\n",
              "       [0.58773863],\n",
              "       [0.5898561 ],\n",
              "       [0.5881874 ],\n",
              "       [0.589619  ],\n",
              "       [0.5892746 ],\n",
              "       [0.5884478 ],\n",
              "       [0.5887718 ],\n",
              "       [0.5884131 ],\n",
              "       [0.5868642 ],\n",
              "       [0.5793407 ],\n",
              "       [0.59027976],\n",
              "       [0.5791807 ],\n",
              "       [0.58195806],\n",
              "       [0.58127016],\n",
              "       [0.5875604 ],\n",
              "       [0.58798   ],\n",
              "       [0.5880241 ],\n",
              "       [0.58955735],\n",
              "       [0.58202434],\n",
              "       [0.5883892 ],\n",
              "       [0.58275515],\n",
              "       [0.5885661 ],\n",
              "       [0.5884396 ],\n",
              "       [0.58186156],\n",
              "       [0.5881049 ],\n",
              "       [0.5892536 ],\n",
              "       [0.5790975 ],\n",
              "       [0.5812343 ],\n",
              "       [0.5881795 ],\n",
              "       [0.5880577 ],\n",
              "       [0.58844715],\n",
              "       [0.588592  ],\n",
              "       [0.57966876],\n",
              "       [0.58760405],\n",
              "       [0.58204776],\n",
              "       [0.58843935],\n",
              "       [0.58772135],\n",
              "       [0.5809963 ],\n",
              "       [0.5896142 ],\n",
              "       [0.5890578 ],\n",
              "       [0.5802504 ],\n",
              "       [0.57939893],\n",
              "       [0.57792956],\n",
              "       [0.58032316],\n",
              "       [0.58763885],\n",
              "       [0.58079267],\n",
              "       [0.5878607 ],\n",
              "       [0.588059  ],\n",
              "       [0.58803946],\n",
              "       [0.5880332 ],\n",
              "       [0.5823315 ],\n",
              "       [0.5819197 ],\n",
              "       [0.58088547],\n",
              "       [0.58122927],\n",
              "       [0.5880391 ],\n",
              "       [0.5822649 ],\n",
              "       [0.580167  ],\n",
              "       [0.5826649 ],\n",
              "       [0.577442  ],\n",
              "       [0.5806896 ],\n",
              "       [0.5818584 ],\n",
              "       [0.5777762 ],\n",
              "       [0.58889735],\n",
              "       [0.58135635],\n",
              "       [0.5817159 ],\n",
              "       [0.58242476],\n",
              "       [0.58168656],\n",
              "       [0.5887097 ],\n",
              "       [0.5829609 ],\n",
              "       [0.58833057],\n",
              "       [0.58096266],\n",
              "       [0.5886998 ],\n",
              "       [0.58920425],\n",
              "       [0.5888457 ],\n",
              "       [0.58870834],\n",
              "       [0.5878757 ],\n",
              "       [0.5885233 ],\n",
              "       [0.58221847],\n",
              "       [0.5887237 ],\n",
              "       [0.58824885],\n",
              "       [0.57764214],\n",
              "       [0.58868706],\n",
              "       [0.58818346],\n",
              "       [0.5887333 ],\n",
              "       [0.58132017],\n",
              "       [0.58745176],\n",
              "       [0.58167446],\n",
              "       [0.58896536],\n",
              "       [0.5813744 ],\n",
              "       [0.58858246],\n",
              "       [0.5881516 ],\n",
              "       [0.587967  ],\n",
              "       [0.587967  ],\n",
              "       [0.5757101 ],\n",
              "       [0.5871405 ],\n",
              "       [0.5818439 ],\n",
              "       [0.58776915],\n",
              "       [0.5883689 ],\n",
              "       [0.5804115 ],\n",
              "       [0.5792996 ],\n",
              "       [0.5890039 ],\n",
              "       [0.5875659 ],\n",
              "       [0.58888274],\n",
              "       [0.5888272 ],\n",
              "       [0.5887474 ],\n",
              "       [0.5826478 ],\n",
              "       [0.58204246],\n",
              "       [0.57790875],\n",
              "       [0.57967377],\n",
              "       [0.5810443 ],\n",
              "       [0.5880888 ],\n",
              "       [0.5888622 ],\n",
              "       [0.58831877],\n",
              "       [0.5820512 ],\n",
              "       [0.578594  ],\n",
              "       [0.5887373 ],\n",
              "       [0.5876224 ],\n",
              "       [0.5878919 ],\n",
              "       [0.58756477],\n",
              "       [0.5886319 ],\n",
              "       [0.5886326 ],\n",
              "       [0.58931094],\n",
              "       [0.5878106 ],\n",
              "       [0.58192694],\n",
              "       [0.5877934 ],\n",
              "       [0.5890922 ],\n",
              "       [0.58820736],\n",
              "       [0.5819663 ],\n",
              "       [0.5802816 ],\n",
              "       [0.58868146],\n",
              "       [0.58843195],\n",
              "       [0.582547  ],\n",
              "       [0.5883067 ],\n",
              "       [0.58907557],\n",
              "       [0.58814365],\n",
              "       [0.5887338 ],\n",
              "       [0.5818924 ],\n",
              "       [0.588807  ],\n",
              "       [0.58229965],\n",
              "       [0.58785945],\n",
              "       [0.58217907],\n",
              "       [0.5808849 ],\n",
              "       [0.58755594],\n",
              "       [0.5809567 ],\n",
              "       [0.58769536],\n",
              "       [0.5826927 ],\n",
              "       [0.5797861 ],\n",
              "       [0.5883567 ],\n",
              "       [0.58787143],\n",
              "       [0.58776677],\n",
              "       [0.58783585],\n",
              "       [0.5888817 ],\n",
              "       [0.5882968 ],\n",
              "       [0.589015  ],\n",
              "       [0.57928246],\n",
              "       [0.5814805 ],\n",
              "       [0.5876244 ],\n",
              "       [0.5882747 ],\n",
              "       [0.5809059 ],\n",
              "       [0.5890029 ],\n",
              "       [0.5871816 ],\n",
              "       [0.58759093],\n",
              "       [0.58829004],\n",
              "       [0.5885339 ],\n",
              "       [0.58027184],\n",
              "       [0.58085096],\n",
              "       [0.5881682 ],\n",
              "       [0.58814454],\n",
              "       [0.58135116],\n",
              "       [0.57812   ],\n",
              "       [0.58758855],\n",
              "       [0.575327  ],\n",
              "       [0.5882011 ],\n",
              "       [0.58841664],\n",
              "       [0.57863796],\n",
              "       [0.5820803 ],\n",
              "       [0.58827686],\n",
              "       [0.58839583],\n",
              "       [0.5875888 ],\n",
              "       [0.5696379 ],\n",
              "       [0.5814645 ],\n",
              "       [0.5894769 ],\n",
              "       [0.58789575],\n",
              "       [0.58860046],\n",
              "       [0.5890009 ],\n",
              "       [0.5812872 ],\n",
              "       [0.5791376 ],\n",
              "       [0.5884076 ],\n",
              "       [0.5888009 ],\n",
              "       [0.5814021 ],\n",
              "       [0.58919334],\n",
              "       [0.5871004 ],\n",
              "       [0.587858  ],\n",
              "       [0.588176  ],\n",
              "       [0.5803926 ],\n",
              "       [0.58122176],\n",
              "       [0.581812  ],\n",
              "       [0.58091336],\n",
              "       [0.5823477 ],\n",
              "       [0.5877099 ],\n",
              "       [0.5740897 ],\n",
              "       [0.5884101 ],\n",
              "       [0.5811465 ],\n",
              "       [0.5887119 ],\n",
              "       [0.5822333 ],\n",
              "       [0.58143854],\n",
              "       [0.58918595],\n",
              "       [0.5891175 ],\n",
              "       [0.5874692 ],\n",
              "       [0.58885545],\n",
              "       [0.5810381 ],\n",
              "       [0.5882891 ],\n",
              "       [0.5894201 ],\n",
              "       [0.58197385],\n",
              "       [0.5868476 ],\n",
              "       [0.58835506],\n",
              "       [0.58100927],\n",
              "       [0.58851266],\n",
              "       [0.5885588 ],\n",
              "       [0.5886287 ],\n",
              "       [0.5891418 ],\n",
              "       [0.5885844 ],\n",
              "       [0.59001225],\n",
              "       [0.581597  ],\n",
              "       [0.58857197],\n",
              "       [0.58851784],\n",
              "       [0.5879694 ],\n",
              "       [0.5815696 ],\n",
              "       [0.5889049 ],\n",
              "       [0.58807385],\n",
              "       [0.58868366],\n",
              "       [0.5898365 ],\n",
              "       [0.58935493],\n",
              "       [0.5893204 ],\n",
              "       [0.5881322 ],\n",
              "       [0.5879575 ],\n",
              "       [0.5884676 ],\n",
              "       [0.58208376],\n",
              "       [0.58903736],\n",
              "       [0.58877087],\n",
              "       [0.5886578 ],\n",
              "       [0.5815159 ],\n",
              "       [0.5886361 ],\n",
              "       [0.5873125 ],\n",
              "       [0.58796966],\n",
              "       [0.5896547 ],\n",
              "       [0.5883837 ],\n",
              "       [0.58892125],\n",
              "       [0.59017307],\n",
              "       [0.58796126],\n",
              "       [0.58893746],\n",
              "       [0.58840084],\n",
              "       [0.5807621 ],\n",
              "       [0.58894104],\n",
              "       [0.58195394],\n",
              "       [0.5890927 ],\n",
              "       [0.5882275 ],\n",
              "       [0.58927166],\n",
              "       [0.58099276],\n",
              "       [0.59033126],\n",
              "       [0.5890878 ],\n",
              "       [0.58878624],\n",
              "       [0.58117735],\n",
              "       [0.588158  ],\n",
              "       [0.5884089 ],\n",
              "       [0.5810435 ],\n",
              "       [0.58807707],\n",
              "       [0.58861226],\n",
              "       [0.5885147 ],\n",
              "       [0.58839744],\n",
              "       [0.58805466],\n",
              "       [0.58145237],\n",
              "       [0.58777916],\n",
              "       [0.5900669 ],\n",
              "       [0.5890778 ],\n",
              "       [0.5891347 ],\n",
              "       [0.5791169 ],\n",
              "       [0.5801033 ],\n",
              "       [0.5823835 ],\n",
              "       [0.5881895 ],\n",
              "       [0.5887788 ],\n",
              "       [0.587742  ],\n",
              "       [0.58894587],\n",
              "       [0.5893258 ],\n",
              "       [0.58856845],\n",
              "       [0.589378  ],\n",
              "       [0.58152425],\n",
              "       [0.5879197 ],\n",
              "       [0.58970577],\n",
              "       [0.5819491 ],\n",
              "       [0.5875415 ],\n",
              "       [0.5813958 ],\n",
              "       [0.588379  ],\n",
              "       [0.5884631 ],\n",
              "       [0.5884119 ],\n",
              "       [0.58860254],\n",
              "       [0.58137625],\n",
              "       [0.57896596],\n",
              "       [0.5889532 ],\n",
              "       [0.58036953],\n",
              "       [0.5885148 ],\n",
              "       [0.5821466 ],\n",
              "       [0.58857876],\n",
              "       [0.58809054],\n",
              "       [0.5775858 ],\n",
              "       [0.5818637 ],\n",
              "       [0.5889056 ],\n",
              "       [0.5881868 ],\n",
              "       [0.58796066],\n",
              "       [0.58135414],\n",
              "       [0.5818484 ],\n",
              "       [0.5817471 ],\n",
              "       [0.5886068 ],\n",
              "       [0.58889073],\n",
              "       [0.5880755 ],\n",
              "       [0.58756244],\n",
              "       [0.5897639 ],\n",
              "       [0.58179015],\n",
              "       [0.5877145 ],\n",
              "       [0.5806795 ],\n",
              "       [0.5813771 ],\n",
              "       [0.58919746],\n",
              "       [0.57991266],\n",
              "       [0.588835  ],\n",
              "       [0.58922595],\n",
              "       [0.5813257 ],\n",
              "       [0.5892185 ],\n",
              "       [0.58992106],\n",
              "       [0.58897364],\n",
              "       [0.58828366],\n",
              "       [0.58148193],\n",
              "       [0.5883132 ],\n",
              "       [0.58853334],\n",
              "       [0.5814652 ],\n",
              "       [0.58874357],\n",
              "       [0.58880734],\n",
              "       [0.5793796 ],\n",
              "       [0.5878426 ],\n",
              "       [0.5880821 ],\n",
              "       [0.58994216],\n",
              "       [0.5828997 ],\n",
              "       [0.5896998 ],\n",
              "       [0.58215654],\n",
              "       [0.58174396],\n",
              "       [0.5815235 ],\n",
              "       [0.5809303 ],\n",
              "       [0.5886512 ],\n",
              "       [0.58260155],\n",
              "       [0.58879924],\n",
              "       [0.58816326],\n",
              "       [0.58906955],\n",
              "       [0.5881099 ],\n",
              "       [0.58970064],\n",
              "       [0.5883423 ],\n",
              "       [0.5887937 ],\n",
              "       [0.58283764],\n",
              "       [0.58289886],\n",
              "       [0.5885415 ],\n",
              "       [0.58877355],\n",
              "       [0.5816122 ],\n",
              "       [0.5882112 ],\n",
              "       [0.58192605],\n",
              "       [0.58868325],\n",
              "       [0.58889884],\n",
              "       [0.58775866],\n",
              "       [0.58220106],\n",
              "       [0.5827374 ],\n",
              "       [0.5825841 ],\n",
              "       [0.5886821 ],\n",
              "       [0.5887943 ],\n",
              "       [0.588324  ],\n",
              "       [0.5877026 ],\n",
              "       [0.5885951 ],\n",
              "       [0.5887104 ],\n",
              "       [0.58888185],\n",
              "       [0.58853066],\n",
              "       [0.58844376],\n",
              "       [0.5883218 ],\n",
              "       [0.58146834],\n",
              "       [0.588317  ],\n",
              "       [0.58795655],\n",
              "       [0.58120286],\n",
              "       [0.58045477],\n",
              "       [0.58169925],\n",
              "       [0.5817923 ],\n",
              "       [0.5880963 ],\n",
              "       [0.58829105],\n",
              "       [0.58812577],\n",
              "       [0.5872126 ],\n",
              "       [0.5887858 ],\n",
              "       [0.5880816 ],\n",
              "       [0.5892174 ],\n",
              "       [0.5889743 ],\n",
              "       [0.5874628 ],\n",
              "       [0.58865803],\n",
              "       [0.5886708 ],\n",
              "       [0.5812913 ],\n",
              "       [0.5899214 ],\n",
              "       [0.5480272 ],\n",
              "       [0.58799607],\n",
              "       [0.53519386],\n",
              "       [0.58833385],\n",
              "       [0.5884801 ],\n",
              "       [0.58838767],\n",
              "       [0.5886796 ],\n",
              "       [0.58123255],\n",
              "       [0.5319412 ],\n",
              "       [0.58832467],\n",
              "       [0.58836824],\n",
              "       [0.5887306 ],\n",
              "       [0.58876747],\n",
              "       [0.5881001 ],\n",
              "       [0.58876586],\n",
              "       [0.5815477 ],\n",
              "       [0.58900267],\n",
              "       [0.5882344 ],\n",
              "       [0.5894041 ],\n",
              "       [0.5877547 ],\n",
              "       [0.5879848 ],\n",
              "       [0.58916587],\n",
              "       [0.5883305 ],\n",
              "       [0.58867335],\n",
              "       [0.5894539 ],\n",
              "       [0.58891016],\n",
              "       [0.5886212 ],\n",
              "       [0.58890706],\n",
              "       [0.58884805],\n",
              "       [0.57831657],\n",
              "       [0.58941925],\n",
              "       [0.5883075 ],\n",
              "       [0.5495034 ],\n",
              "       [0.5887921 ],\n",
              "       [0.5899485 ],\n",
              "       [0.5890539 ],\n",
              "       [0.58763343],\n",
              "       [0.58978695],\n",
              "       [0.58193606],\n",
              "       [0.58907324],\n",
              "       [0.588714  ],\n",
              "       [0.5894848 ],\n",
              "       [0.5896617 ],\n",
              "       [0.5887279 ],\n",
              "       [0.5893044 ],\n",
              "       [0.5887106 ],\n",
              "       [0.58836794],\n",
              "       [0.5895128 ],\n",
              "       [0.5886242 ],\n",
              "       [0.58158374],\n",
              "       [0.5880099 ],\n",
              "       [0.5906446 ],\n",
              "       [0.58857435],\n",
              "       [0.5793559 ],\n",
              "       [0.58865005],\n",
              "       [0.5891333 ],\n",
              "       [0.581371  ],\n",
              "       [0.58865505],\n",
              "       [0.58832157],\n",
              "       [0.5888307 ],\n",
              "       [0.58870995],\n",
              "       [0.5823067 ],\n",
              "       [0.58831567],\n",
              "       [0.5894496 ],\n",
              "       [0.5884993 ],\n",
              "       [0.58784527],\n",
              "       [0.58956224],\n",
              "       [0.58940303],\n",
              "       [0.58918506],\n",
              "       [0.58926094],\n",
              "       [0.58865213],\n",
              "       [0.58862036],\n",
              "       [0.5892236 ],\n",
              "       [0.5785281 ],\n",
              "       [0.58924013],\n",
              "       [0.58912975],\n",
              "       [0.5885081 ],\n",
              "       [0.5892895 ],\n",
              "       [0.58897954],\n",
              "       [0.5883465 ],\n",
              "       [0.5896889 ],\n",
              "       [0.5809944 ],\n",
              "       [0.5799031 ],\n",
              "       [0.58777976],\n",
              "       [0.5812779 ],\n",
              "       [0.5820496 ],\n",
              "       [0.5820392 ],\n",
              "       [0.58922005],\n",
              "       [0.58836645],\n",
              "       [0.58765054],\n",
              "       [0.5880503 ],\n",
              "       [0.5878201 ],\n",
              "       [0.58956367],\n",
              "       [0.5885283 ],\n",
              "       [0.5885245 ],\n",
              "       [0.58174425],\n",
              "       [0.58851784],\n",
              "       [0.58786494],\n",
              "       [0.58912057],\n",
              "       [0.58938074],\n",
              "       [0.58815986],\n",
              "       [0.5888074 ],\n",
              "       [0.5885877 ],\n",
              "       [0.5878734 ],\n",
              "       [0.58866864],\n",
              "       [0.58151543],\n",
              "       [0.5890463 ],\n",
              "       [0.5879153 ],\n",
              "       [0.58817035],\n",
              "       [0.58916485],\n",
              "       [0.588204  ],\n",
              "       [0.58867055],\n",
              "       [0.58946574],\n",
              "       [0.58798605],\n",
              "       [0.5813374 ],\n",
              "       [0.58890826],\n",
              "       [0.5814364 ],\n",
              "       [0.5877755 ],\n",
              "       [0.5884981 ],\n",
              "       [0.5891048 ],\n",
              "       [0.58788794],\n",
              "       [0.58170265],\n",
              "       [0.5884559 ],\n",
              "       [0.5884625 ],\n",
              "       [0.581816  ],\n",
              "       [0.58887887],\n",
              "       [0.58876795],\n",
              "       [0.58928996],\n",
              "       [0.5884285 ],\n",
              "       [0.5880095 ],\n",
              "       [0.58818406],\n",
              "       [0.5891726 ],\n",
              "       [0.58705646],\n",
              "       [0.58849174],\n",
              "       [0.5827504 ],\n",
              "       [0.5887626 ],\n",
              "       [0.58787084],\n",
              "       [0.5887295 ],\n",
              "       [0.5889132 ],\n",
              "       [0.5883925 ],\n",
              "       [0.58769715],\n",
              "       [0.58142203],\n",
              "       [0.5899747 ],\n",
              "       [0.58937746],\n",
              "       [0.5876348 ],\n",
              "       [0.5880306 ],\n",
              "       [0.5882526 ],\n",
              "       [0.5878302 ],\n",
              "       [0.58826375],\n",
              "       [0.5820574 ],\n",
              "       [0.58825046],\n",
              "       [0.58028257],\n",
              "       [0.58102703],\n",
              "       [0.58854264],\n",
              "       [0.58816683],\n",
              "       [0.58854574],\n",
              "       [0.5889072 ],\n",
              "       [0.5887869 ],\n",
              "       [0.5814153 ],\n",
              "       [0.5884591 ],\n",
              "       [0.5821016 ],\n",
              "       [0.5891706 ],\n",
              "       [0.5887555 ],\n",
              "       [0.5812697 ],\n",
              "       [0.5890969 ],\n",
              "       [0.58817714],\n",
              "       [0.58712643],\n",
              "       [0.5793956 ],\n",
              "       [0.5812684 ],\n",
              "       [0.58828497],\n",
              "       [0.5887568 ],\n",
              "       [0.5875985 ],\n",
              "       [0.5885046 ],\n",
              "       [0.5879927 ],\n",
              "       [0.58818406],\n",
              "       [0.587724  ],\n",
              "       [0.58821553],\n",
              "       [0.5893039 ],\n",
              "       [0.5881446 ],\n",
              "       [0.58819014],\n",
              "       [0.5886976 ],\n",
              "       [0.5819832 ],\n",
              "       [0.5880429 ],\n",
              "       [0.5877793 ],\n",
              "       [0.58839744],\n",
              "       [0.5893358 ],\n",
              "       [0.58136165],\n",
              "       [0.5892592 ],\n",
              "       [0.58763796],\n",
              "       [0.5802973 ],\n",
              "       [0.5880663 ],\n",
              "       [0.5876039 ],\n",
              "       [0.58791685],\n",
              "       [0.58865345],\n",
              "       [0.58196133],\n",
              "       [0.58827007],\n",
              "       [0.5886152 ],\n",
              "       [0.5804211 ],\n",
              "       [0.5886574 ],\n",
              "       [0.5880629 ],\n",
              "       [0.5884708 ],\n",
              "       [0.58868474],\n",
              "       [0.58822024],\n",
              "       [0.58833504],\n",
              "       [0.58136076],\n",
              "       [0.58911926],\n",
              "       [0.5822333 ],\n",
              "       [0.58828986],\n",
              "       [0.58787614],\n",
              "       [0.5903758 ],\n",
              "       [0.587695  ],\n",
              "       [0.58839506],\n",
              "       [0.5816596 ],\n",
              "       [0.5813391 ],\n",
              "       [0.589872  ],\n",
              "       [0.5812669 ],\n",
              "       [0.5882677 ],\n",
              "       [0.58820957],\n",
              "       [0.58913946],\n",
              "       [0.58869237],\n",
              "       [0.58064634],\n",
              "       [0.59001863],\n",
              "       [0.5883994 ],\n",
              "       [0.58812016],\n",
              "       [0.5888506 ],\n",
              "       [0.58910483],\n",
              "       [0.58919394],\n",
              "       [0.578795  ],\n",
              "       [0.5875993 ],\n",
              "       [0.58035755],\n",
              "       [0.5743577 ],\n",
              "       [0.5805866 ],\n",
              "       [0.5886207 ],\n",
              "       [0.5815739 ],\n",
              "       [0.5887173 ],\n",
              "       [0.5880648 ],\n",
              "       [0.5885347 ],\n",
              "       [0.58189946],\n",
              "       [0.58838224],\n",
              "       [0.58758146],\n",
              "       [0.5885659 ],\n",
              "       [0.588729  ],\n",
              "       [0.58264494],\n",
              "       [0.5880225 ],\n",
              "       [0.5873677 ],\n",
              "       [0.5891591 ],\n",
              "       [0.58183306],\n",
              "       [0.5782366 ],\n",
              "       [0.5882622 ],\n",
              "       [0.58880466],\n",
              "       [0.5799396 ],\n",
              "       [0.58925676],\n",
              "       [0.58167356],\n",
              "       [0.58203965],\n",
              "       [0.58832675],\n",
              "       [0.5783524 ],\n",
              "       [0.58962137],\n",
              "       [0.5877703 ],\n",
              "       [0.582685  ],\n",
              "       [0.5899213 ]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SAg8Rn8VrJJ_"
      },
      "source": [
        " F1 SCORE를 바탕으로 성능 측정  \n",
        "F1 SCORE는 precision과 recall을 가중평균하여 계산합니다  \n",
        "recall은 (모델이 TRUE라고 판정한 것의 숫자)/(전체 TRUE의 숫자)  \n",
        "precision은 (진짜 TRUE) / (모델이 TRUE라고 판정한 것의 숫자)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ybYV6QLrHA2",
        "outputId": "84d49112-d820-460b-c29e-a349345f3afb"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_true = test['label']\n",
        "# F1 Score 확인\n",
        "print(classification_report(y_true, np.round(preds,0)))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       325\n",
            "           1       0.52      1.00      0.68       352\n",
            "\n",
            "    accuracy                           0.52       677\n",
            "   macro avg       0.26      0.50      0.34       677\n",
            "weighted avg       0.27      0.52      0.36       677\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-tj3FQ6rRPa"
      },
      "source": [
        "import logging\n",
        "tf.get_logger().setLevel(logging.ERROR)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I6NI3j_eLp4B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}